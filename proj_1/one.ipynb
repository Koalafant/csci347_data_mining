{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - EDA \n",
    "#### Mason Reyher, Jamison Cleveland, Kade Aldrich, Mitch Froelich, Ryley Ourada"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip -q\n",
    "%pip install pandas -q\n",
    "%pip install numpy -q \n",
    "%pip install matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a well-written paragraph, answer the following questions about the data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the data used for? </br>\n",
    "**Two datasets are included, related to red and white (We only used the red for our project) vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests. The proposal of the data usage was to predict human wine taste preferences that is based on easily available analytical tests at the certification step.** </br>\n",
    "**Additional Info: The two datasets are related to red and white variants of the Portuguese (We only used the red variants in our study) \\\"Vinho Verde\\\" wine. For more details, consult: [Web Link] or the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who (or what organization) uploaded the data?</br>\n",
    "**Paulo Cortez, University of Minho, Guimar√£es, Portugal, http://www3.dsi.uminho.pt/pcortez**\n",
    "**A. Cerdeira, F. Almeida, T. Matos and J. Reis, Viticulture Commission of the Vinho Verde Region(CVRVV), Porto, Portugal**\n",
    "**@2009**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many attributes and how many entities are represented in the data? </br>\n",
    "**12 Attributes** </br>\n",
    "**The dataset has 4898 instances.**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many numerical attributes? </br>\n",
    "**12**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many categorical attributes? </br>\n",
    "**0 (Grape types, wine brand, ect were not present in the submitted data recieved from website)**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you suggest that each categorical attribute be label-encoded or one-hot-\n",
    "encoded? Why? </br>\n",
    "**All categorical variables should be label encoded, not one-hot encoded. All variables are ranked via quality (Scored between 0 and 10). - for example, the number of a wine 'pH' field is given as a number between 0-14. This is perfect for label-encoding. All other categorical variables assume this pattern as well.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there missing values in the data? If so, what proportion of the data is missing\n",
    "overall? What proportion of data is missing per attribute (you may use a plot or table to\n",
    "summarize this information)?\n",
    "</br>\n",
    "**There is no missing data.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this data set interesting to you?\n",
    "</br>\n",
    "**The data set is interesting to us because the wine industry is one the largest in the world. Almost every country across the globe has some type or variation of wine that is unique in flavour. The goal of this data was to make it possibly predicatable for companies to gauge the preferences of their buyers and enjoyers. Trying to predict human preference in a incredibly interesting idea as every human is different, but we can gather if more people prefer an aspect over an other using data mining.**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the attributes used to describe this data, which do you think are the most\n",
    "descriptive of the data and why (before doing any data analysis) ?\n",
    "</br>\n",
    "**The 'alcohol' and 'residual sugars' attributes seem to be the most important. Before doing analysis, it would be probable to assume the more alcohol a wine consists of, the more it would be either like or disliked, based on the general knowledge that some people will not like the taste of alcohol. The residual sugars falls into this realm as well with some people preferring a sugary wine over a bitter wine. Most attributes can fairly important for a wine, so the least important is likely the 'pH' (acidity gauge) attribute, due to fields like fixed acidity and volatile acidity being similar in nature.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Python to write the following functions, without using any functions with the same purpose\n",
    "in sklearn, pandas, numpy, or any other library (though you may want to use these libraries to\n",
    "check your answers):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will compute the mean of a numerical, multidimensional data set\n",
    "input as a 2-dimensional numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input needs to be a 2d numpy array\n",
    "def get_vector_mean(arr):\n",
    "    return arr.sum(axis=0) / arr.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will compute the sample covariance between two attributes that are\n",
    "input as one-dimensional numpy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov(attr_1, attr_2):\n",
    "    attr_1_mean = float(sum(attr_1)) / len(attr_1) \n",
    "    attr_2_mean = float(sum(attr_2)) / len(attr_2) \n",
    "    sum_of = 0\n",
    "    for i in range(len(attr_1)):\n",
    "        sum_of += (float(attr_1[i]) - attr_1_mean) * (float(attr_2[i]) - attr_2_mean)\n",
    "    sum_of /= len(attr_1) - 1\n",
    "    return sum_of\n",
    "\n",
    "def get_var(arr):\n",
    "    return np.apply_along_axis(lambda x: get_cov(x, x), 0, arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will compute the correlation between two attributes that are input as\n",
    "two numpy vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr(attr_1, attr_2):\n",
    "    attr_1_mean = float(sum(attr_1)) / len(attr_1) \n",
    "    attr_2_mean = float(sum(attr_2)) / len(attr_2)\n",
    "    # find standard deviation\n",
    "    attr_1_dev = 0\n",
    "    attr_2_dev = 0\n",
    "    for i in range(len(attr_1)):\n",
    "        attr_1_dev += (attr_1[i] - attr_1_mean)**2\n",
    "        attr_2_dev += (attr_2[i] - attr_2_mean)**2\n",
    "    attr_1_dev = math.sqrt(attr_1_dev / len(attr_1))\n",
    "    attr_2_dev = math.sqrt(attr_2_dev / len(attr_2))\n",
    "\n",
    "    # standardize values\n",
    "    for i in range(len(attr_1)):\n",
    "        attr_1[i] = (attr_1[i] - attr_1_mean) / attr_1_dev\n",
    "        attr_2[i] = (attr_2[i] - attr_2_mean) / attr_2_dev\n",
    "   \n",
    "    num = 0\n",
    "    den_x = 0\n",
    "    den_y = 0\n",
    "    # calculate numerator and denominators\n",
    "    for i in range(len(attr_1)):\n",
    "        num += (float(attr_1[i]) - attr_1_mean) * (float(attr_2[i]) - attr_2_mean)\n",
    "        den_x += (float(attr_1[i]) - attr_1_mean)**2\n",
    "        den_y += (float(attr_2[i]) - attr_2_mean)**2\n",
    "    # calculate full denominator\n",
    "    den = den_x * den_y\n",
    "    return num / den"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will normalize the attributes in a two-dimensional numpy array using\n",
    "range normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range_norm(arr):\n",
    "    max_ = arr.max(0)\n",
    "    min_ = arr.min(0)\n",
    "    return (arr - min_) / (max_ - min_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will normalize the attributes in a two-dimensional numpy array using\n",
    "standard normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard normalization is the z-score normalization\n",
    "# https://en.wikipedia.org/wiki/Normalization_(statistics)#Examples\n",
    "# https://en.wikipedia.org/wiki/Standard_score\n",
    "def get_standard_norm(arr):\n",
    "    mu = get_vector_mean(arr)\n",
    "    sigma = np.sqrt(get_var(arr))\n",
    "    return (arr - mu) / sigma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will compute the covariance matrix of a data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_matrix(df):\n",
    "    return np.stack([np.array([get_cov(df[attr1], df[attr2]) for attr2 in df]) for attr1 in df])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will label-encode a two-dimensional categorical data array that is\n",
    "passed in as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(attr):\n",
    "    attr = list(attr)\n",
    "    key_list = set(attr)\n",
    "    keys = {}\n",
    "    count = 0\n",
    "    for key in key_list:\n",
    "        keys[key] = count\n",
    "        count+=1\n",
    "    for i, val in enumerate(attr):\n",
    "        attr[i] = keys[val]\n",
    "    return np.array(attr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('wines_red.csv', sep=\";\")\n",
    "df_orig.columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide','density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "df_orig['quality'] = label_encode(df_orig['quality'])\n",
    "df_orig.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the multivariate mean of the numerical data matrix (where categorical data\n",
    "have been converted to numerical values)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_orig.copy()\n",
    "get_vector_mean(df_copy.to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the covariance matrix of the numerical data matrix (where categorical data\n",
    "have been converted to numerical values)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy2 = df_orig.copy()\n",
    "get_cov_matrix(df_copy2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose 5 pairs of attributes that you think could be related. Create scatter plots of\n",
    "all 5 pairs and include these in your report, along with a description and analysis that\n",
    "summarizes why these pairs of attributes might be related, and how the scatter plots do or\n",
    "do not support this intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which range-normalized numerical attributes have the greatest sample covariance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range_normalized = pd.DataFrame(get_range_norm(df_orig.to_numpy()), columns=df_orig.columns)\n",
    "covar_matrix = get_cov_matrix(df_range_normalized)\n",
    "\n",
    "# mask used later to get the upper diagonal values from our matrices\n",
    "triu_mask = np.zeros_like(covar_matrix, dtype=np.bool_)\n",
    "triu_mask[np.triu_indices_from(covar_matrix, k=1)] = True\n",
    "\n",
    "# set diagonals to -inf so we only get max of off-diagonals\n",
    "\n",
    "# take the flat index to the array,\n",
    "# get the indicies for each attribute,\n",
    "# then return the labels for each attribute\n",
    "covar_flat_idx = np.where(triu_mask, covar_matrix, -math.inf).argmax()\n",
    "covar_shape_idx = np.unravel_index(covar_flat_idx, df_range_normalized.shape)\n",
    "[covar_label1, covar_label2] = [df_range_normalized.columns[i] for i in covar_shape_idx]\n",
    "covar_label1, covar_label2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is their sample covariance? Create a scatter plot of these range-normalized attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_matrix[covar_shape_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_range_normalized[covar_label1]\n",
    "y = df_range_normalized[covar_label2]\n",
    "plt.xlabel(covar_label1)\n",
    "plt.ylabel(covar_label2)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Z-score-normalized numerical attributes have the greatest correlation? What\n",
    "is their correlation? Create a scatter plot of these Z-score-normalized attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard_normalized = pd.DataFrame(data=get_standard_norm(df_orig.to_numpy()), columns=df_orig.columns)\n",
    "df_standard_normalized.to_numpy()\n",
    "\n",
    "# same thing as the covariance, just with correlation\n",
    "# correlation matrix is just covariance matrix of the z-score-normalized data\n",
    "corr_matrix = get_cov_matrix(df_standard_normalized)\n",
    "\n",
    "corr_flat_idx = np.where(triu_mask, corr_matrix, -math.inf).argmax()\n",
    "corr_shape_idx = np.unravel_index(corr_flat_idx, df_standard_normalized.shape)\n",
    "[corr_label1, corr_label2] = [df_standard_normalized.columns[i] for i in corr_shape_idx]\n",
    "\n",
    "corr_label1, corr_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_standard_normalized[corr_label1]\n",
    "y = df_standard_normalized[corr_label2]\n",
    "plt.xlabel(corr_label1)\n",
    "plt.ylabel(corr_label2)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Z-score-normalized numerical attributes have the smallest correlation? What\n",
    "is their correlation? Create a scatter plot of these Z-score-normalized attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_flat_idx = np.where(triu_mask, corr_matrix, math.inf).argmin()\n",
    "corr_shape_idx = np.unravel_index(corr_flat_idx, df_standard_normalized.shape)\n",
    "[corr_label3, corr_label4] = [df_standard_normalized.columns[i] for i in corr_shape_idx]\n",
    "\n",
    "(corr_label3, corr_label4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_standard_normalized[corr_label3]\n",
    "y = df_standard_normalized[corr_label4]\n",
    "plt.xlabel(corr_label3)\n",
    "plt.ylabel(corr_label4)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many pairs of features have correlation greater than or equal to 0.5?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_orig.copy()\n",
    "columns = df_copy.columns\n",
    "column_check = {x : False for x in columns}\n",
    "for column_1 in columns:\n",
    "    for column_2 in columns:\n",
    "        if column_1 == column_2 or not column_check[column_2]:\n",
    "            continue\n",
    "        # reset df because I don't understand references\n",
    "        df_copy = df_orig.copy()\n",
    "        print(f'Columns -> {column_1} - {column_2} -> correlation: {get_corr(df_copy[column_1], df_copy[column_2])}')\n",
    "    column_check[column_1] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No pairs of features have a correlation of >= 0.5.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many pairs of features have negative sample covariance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the total variance of the data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_var(arr):\n",
    "    vec_var = get_var(arr)\n",
    "    return vec_var.sum()\n",
    "df_copy3 = df_orig.copy()\n",
    "get_total_var(df_copy3.to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the total variance of the data, restricted to the five features that have the\n",
    "greatest sample variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
