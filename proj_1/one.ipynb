{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - EDA \n",
    "#### Mason Reyher, Jamison Cleveland, Kade Aldrich, Mitch Froelich, Ryley Ourada"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip -q\n",
    "%pip install pandas -q\n",
    "%pip install numpy -q \n",
    "%pip install matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a well-written paragraph, answer the following questions about the data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the data used for? </br>\n",
    "**This data was used in a paper about multi-attribute decision making (Neural nets, trees, etc.) (8th Intl Workshop on Expert\n",
    "   Systems and their Applications, Avignon, France. pages 59-78, 1988).** </br>\n",
    "**It was also used for, \"the evaluation\n",
    "   of HINT (Hierarchy INduction Tool)\" (B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by\n",
    "   function decomposition. ICML-97, Nashville, TN. 1997).**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who (or what organization) uploaded the data?</br>\n",
    "**Marko Bohanec and Blaz Zupan, June 1997**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many attributes and how many entities are represented in the data? </br>\n",
    "**6 Attributes officially; for our purposes, 7, because of the 'class' attribute.** </br>\n",
    "**The dataset has 1728 instances.**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many numerical attributes? </br>\n",
    "**2**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many categorical attributes? </br>\n",
    "**5**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you suggest that each categorical attribute be label-encoded or one-hot-\n",
    "encoded? Why? </br>\n",
    "**All categorical variables should be label encoded, not one-hot encoded. All variables are ranked via quality - for example, the price of a car 'buying' field is given a v-high, high, med, or low value. This is perfect for label-encoding. All other categorical variables assume this pattern as well.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there missing values in the data? If so, what proportion of the data is missing\n",
    "overall? What proportion of data is missing per attribute (you may use a plot or table to\n",
    "summarize this information)?\n",
    "</br>\n",
    "**There is no missing data.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this data set interesting to you?\n",
    "</br>\n",
    "**ANSWER HERE**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the attributes used to describe this data, which do you think are the most\n",
    "descriptive of the data and why (before doing any data analysis) ?\n",
    "</br>\n",
    "**the 'buying' and 'safety' attributes seem to be the most important. Before doing analysis, it would be probable to assume the more safe a car is, the more it would be worth. Most attributes are fairly important for a car (maintenace costs...), so the least important is likely the 'lug_boot' (trunk size) attribute, due to fields like cost and safety being much more important.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Python to write the following functions, without using any functions with the same purpose\n",
    "in sklearn, pandas, numpy, or any other library (though you may want to use these libraries to\n",
    "check your answers):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will compute the mean of a numerical, multidimensional data set\n",
    "input as a 2-dimensional numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input needs to be a 2d numpy array\n",
    "def get_vector_mean(arr):\n",
    "    return arr.sum(axis=0) / arr.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will compute the sample covariance between two attributes that are\n",
    "input as one-dimensional numpy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov(attr_1, attr_2):\n",
    "    attr_1_mean = float(sum(attr_1)) / len(attr_1) \n",
    "    attr_2_mean = float(sum(attr_2)) / len(attr_2) \n",
    "    sum_of = 0\n",
    "    for i in range(len(attr_1)):\n",
    "        sum_of += (float(attr_1[i]) - attr_1_mean) * (float(attr_2[i]) - attr_2_mean)\n",
    "    sum_of /= len(attr_1) - 1\n",
    "    return sum_of\n",
    "\n",
    "def get_var(arr):\n",
    "    return np.apply_along_axis(lambda x: get_cov(x, x), 0, arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will compute the correlation between two attributes that are input as\n",
    "two numpy vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr(attr_1, attr_2):\n",
    "    attr_1_mean = float(sum(attr_1)) / len(attr_1) \n",
    "    attr_2_mean = float(sum(attr_2)) / len(attr_2)\n",
    "    # find standard deviation\n",
    "    attr_1_dev = 0\n",
    "    attr_2_dev = 0\n",
    "    for i in range(len(attr_1)):\n",
    "        attr_1_dev += (attr_1[i] - attr_1_mean)**2\n",
    "        attr_2_dev += (attr_2[i] - attr_2_mean)**2\n",
    "    attr_1_dev = math.sqrt(attr_1_dev / len(attr_1))\n",
    "    attr_2_dev = math.sqrt(attr_2_dev / len(attr_2))\n",
    "\n",
    "    # standardize values\n",
    "    for i in range(len(attr_1)):\n",
    "        attr_1[i] = (attr_1[i] - attr_1_mean) / attr_1_dev\n",
    "        attr_2[i] = (attr_2[i] - attr_2_mean) / attr_2_dev\n",
    "   \n",
    "    num = 0\n",
    "    den_x = 0\n",
    "    den_y = 0\n",
    "    # calculate numerator and denominators\n",
    "    for i in range(len(attr_1)):\n",
    "        num += (float(attr_1[i]) - attr_1_mean) * (float(attr_2[i]) - attr_2_mean)\n",
    "        den_x += (float(attr_1[i]) - attr_1_mean)**2\n",
    "        den_y += (float(attr_2[i]) - attr_2_mean)**2\n",
    "    # calculate full denominator\n",
    "    den = den_x * den_y\n",
    "    return num / den"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will normalize the attributes in a two-dimensional numpy array using\n",
    "range normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range_norm(arr):\n",
    "    max_ = arr.max(0)\n",
    "    min_ = arr.min(0)\n",
    "    return (arr - min_) / (max_ - min_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will normalize the attributes in a two-dimensional numpy array using\n",
    "standard normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard normalization is the z-score normalization\n",
    "# https://en.wikipedia.org/wiki/Normalization_(statistics)#Examples\n",
    "# https://en.wikipedia.org/wiki/Standard_score\n",
    "def get_standard_norm(arr):\n",
    "    mu = get_vector_mean(arr)\n",
    "    sigma = np.sqrt(get_var(arr))\n",
    "    return (arr - mu) / sigma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will compute the covariance matrix of a data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_matrix(df):\n",
    "    return np.stack([np.array([get_cov(df[attr1], df[attr2]) for attr2 in df]) for attr1 in df])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that will label-encode a two-dimensional categorical data array that is\n",
    "passed in as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(attr):\n",
    "    attr = list(attr)\n",
    "    key_list = set(attr)\n",
    "    keys = {}\n",
    "    count = 0\n",
    "    for key in key_list:\n",
    "        keys[key] = count\n",
    "        count+=1\n",
    "    for i, val in enumerate(attr):\n",
    "        attr[i] = keys[val]\n",
    "    return np.array(attr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('wines_red.csv', sep=\";\")\n",
    "df_orig.columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide','density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "df_orig['quality'] = label_encode(df_orig['quality'])\n",
    "df_orig.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the multivariate mean of the numerical data matrix (where categorical data\n",
    "have been converted to numerical values)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_orig.copy()\n",
    "get_vector_mean(df_copy.to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the covariance matrix of the numerical data matrix (where categorical data\n",
    "have been converted to numerical values)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy2 = df_orig.copy()\n",
    "get_cov_matrix(df_copy2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose 5 pairs of attributes that you think could be related. Create scatter plots of\n",
    "all 5 pairs and include these in your report, along with a description and analysis that\n",
    "summarizes why these pairs of attributes might be related, and how the scatter plots do or\n",
    "do not support this intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which range-normalized numerical attributes have the greatest sample covariance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range_normalized = pd.DataFrame(get_range_norm(df_orig.to_numpy()), columns=df_orig.columns)\n",
    "covar_matrix = get_cov_matrix(df_range_normalized)\n",
    "\n",
    "# set diagonals to -inf so we only get max of off-diagonals\n",
    "np.fill_diagonal(covar_matrix, -math.inf)\n",
    "\n",
    "# take the flat index to the array,\n",
    "# get the indicies for each attribute,\n",
    "# then return the labels for each attribute\n",
    "covar_flat_idx = covar_matrix.argmax()\n",
    "covar_shape_idx = np.unravel_index(covar_flat_idx, df_range_normalized.shape)\n",
    "[covar_label1, covar_label2] = [df_range_normalized.columns[i] for i in covar_shape_idx]\n",
    "covar_label1, covar_label2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is their sample covariance? Create a scatter plot of these range-normalized attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_matrix[covar_shape_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_range_normalized[covar_label1]\n",
    "y = df_range_normalized[covar_label2]\n",
    "plt.xlabel(covar_label1)\n",
    "plt.ylabel(covar_label2)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Z-score-normalized numerical attributes have the greatest correlation? What\n",
    "is their correlation? Create a scatter plot of these Z-score-normalized attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard_normalized = pd.DataFrame(data=get_standard_norm(df_orig.to_numpy()), columns=df_orig.columns)\n",
    "df_standard_normalized.to_numpy()\n",
    "\n",
    "# same thing as the covariance, just with correlation\n",
    "# correlation matrix is just covariance matrix of the z-score-normalized data\n",
    "corr_matrix = get_cov_matrix(df_standard_normalized)\n",
    "np.fill_diagonal(corr_matrix, -math.inf)\n",
    "\n",
    "corr_flat_idx = corr_matrix.argmax()\n",
    "corr_shape_idx = np.unravel_index(corr_flat_idx, df_standard_normalized.shape)\n",
    "[corr_label1, corr_label2] = [df_standard_normalized.columns[i] for i in corr_shape_idx]\n",
    "\n",
    "corr_label1, corr_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_standard_normalized[corr_label1]\n",
    "y = df_standard_normalized[corr_label2]\n",
    "plt.xlabel(corr_label1)\n",
    "plt.ylabel(corr_label2)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Z-score-normalized numerical attributes have the smallest correlation? What\n",
    "is their correlation? Create a scatter plot of these Z-score-normalized attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(corr_matrix, math.inf)\n",
    "corr_flat_idx = corr_matrix.argmin()\n",
    "corr_shape_idx = np.unravel_index(corr_flat_idx, df_standard_normalized.shape)\n",
    "[corr_label3, corr_label4] = [df_standard_normalized.columns[i] for i in corr_shape_idx]\n",
    "\n",
    "(corr_label3, corr_label4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_standard_normalized[corr_label3]\n",
    "y = df_standard_normalized[corr_label4]\n",
    "plt.xlabel(corr_label3)\n",
    "plt.ylabel(corr_label4)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many pairs of features have correlation greater than or equal to 0.5?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_orig.copy()\n",
    "columns = df_copy.columns\n",
    "column_check = {x : False for x in columns}\n",
    "for column_1 in columns:\n",
    "    for column_2 in columns:\n",
    "        if column_1 == column_2 or not column_check[column_2]:\n",
    "            continue\n",
    "        # reset df because I don't understand references\n",
    "        df_copy = df_orig.copy()\n",
    "        print(f'Columns -> {column_1} - {column_2} -> correlation: {get_corr(df_copy[column_1], df_copy[column_2])}')\n",
    "    column_check[column_1] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No pairs of features have a correlation of >= 0.5.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many pairs of features have negative sample covariance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the total variance of the data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_var(arr):\n",
    "    vec_var = get_var(arr)\n",
    "    return vec_var.sum()\n",
    "df_copy3 = df_orig.copy()\n",
    "get_total_var(df_copy3.to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the total variance of the data, restricted to the five features that have the\n",
    "greatest sample variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
